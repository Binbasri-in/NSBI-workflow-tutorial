{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsandesara_umass_edu/.conda/envs/nsbi_env/lib/python3.9/site-packages/nsbi_common_utils/plotting.py:11: FutureWarning: ``set_style`` is deprecated: Naming convention is changing to match mpl. Use ``mplhep.style.use()``.\n",
      "  hep.set_style(\"ATLAS\")\n",
      "2025-08-09 00:34:00.296929: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-09 00:34:00.729423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-09 00:34:00.807048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-09 00:34:00.832044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-09 00:34:01.356700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pathlib, importlib\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load the package and modules for training and plotting\n",
    "import nsbi_common_utils\n",
    "from nsbi_common_utils import plotting, training\n",
    "from nsbi_common_utils.training import TrainEvaluate_NN, TrainEvaluatePreselNN\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_jit(False)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "from utils import preselection_using_score, calculate_preselection_observable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "hep.style.use(hep.style.ATLAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PATH_PREFIX = config[\"PATH_PREFIX\"]\n",
    "PATH_TO_SAVED_DATA = config[\"PATH_SAVED_DATA\"]\n",
    "\n",
    "PATH_PRESEL_MODEL = PATH_TO_SAVED_DATA + 'preselection_model/'\n",
    "\n",
    "config.update(\n",
    "    {\n",
    "        \"PATH_PRESEL_MODEL\": PATH_PRESEL_MODEL\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau']\n",
      "['ttbar', 'ztautau']\n"
     ]
    }
   ],
   "source": [
    "# Get the dictionary of labels to processes\n",
    "labels_dict = config[\"PROCESS_TO_INT_LABELS_DICT\"]\n",
    "\n",
    "# Signal processes in the model\n",
    "signal_processes = config[\"SIGNAL_PROCESSES\"]\n",
    "\n",
    "# Background processes in the model\n",
    "background_processes = config[\"BACKGROUND_PROCESSES\"]\n",
    "\n",
    "print(signal_processes)\n",
    "print(background_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If the preselection NN has already been trained and saved, load from the saved model\n",
    "USE_SAVED_MODEL_PRESEL = False\n",
    "\n",
    "# If the preselection NN has already been trained and evaluated, load the numpy array of predictions\n",
    "USE_SAVED_PRESEL_PREDICTIONS = False\n",
    "\n",
    "# Input features for training\n",
    "features = config[\"TRAINING_FEATURES\"]\n",
    "\n",
    "# Subset of the features to standardize before training\n",
    "features_scaling = config[\"TRAINING_FEATURES_TO_SCALE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the nominal dataset saved from the pre-processing notebook\n",
    "\n",
    "path_to_nominal_dataframe = config[\"PATH_TO_nominal_DATA\"]\n",
    "dataset_incl_nominal = pd.read_hdf(path_to_nominal_dataframe, key=\"dataset\", mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MC/data weights and training labels identifying different processes\n",
    "weights         = dataset_incl_nominal[\"weights\"].to_numpy()\n",
    "train_labels    = dataset_incl_nominal[\"train_labels\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the training weights - only discriminating shapes\n",
    "weights_normed  = weights.copy()\n",
    "\n",
    "for key in labels_dict:\n",
    "\n",
    "    weights_normed[train_labels==labels_dict[key]] /= weights[train_labels==labels_dict[key]].sum()\n",
    "\n",
    "dataset_incl_nominal['weights_normed'] = weights_normed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Preselection NN\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choice of reference sample**\n",
    "\n",
    "The density ratios need to be trained on phase space regions with support for the reference hypothesis $p_{ref}(x) > 0$.\n",
    "\n",
    "To ensure this, we make a selection that selects events in the phase space regions with $p_{ref}(x) > 0$, or $p_c(x) \\gg p_{ref}(x)$, and only perform the NSBI fit in this selected analysis region. **A natural choice for the reference hypothesis is then the signal-rich hypotheses**. This is referred to in the ATLAS publications as the Search-Oriented Mixture Models approach: \n",
    "\n",
    "$$p_{ref}(x) = \\frac{1}{\\sum_S \\nu_S} \\sum_S \\frac{d\\sigma_S}{dx} = \\frac{1}{\\nu_{H \\to \\tau\\tau}} \\frac{d\\sigma_{H \\to \\tau\\tau}}{dx}$$\n",
    "\n",
    "where the sum runs over all signal hypothesis in the model and the second equality is due to the sole signal hypothesis in our toy model, $pp \\to {t\\bar{t}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau']\n"
     ]
    }
   ],
   "source": [
    "# What are the signal processes in the user-provided model?\n",
    "print(signal_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau', 'ttbar']\n"
     ]
    }
   ],
   "source": [
    "# The reference hypothesis is chosen as the sum of signal hypothesis\n",
    "ref_processes = config[\"REFERENCE_PROCESSES\"]\n",
    "print(ref_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting out regions with $p_{ref}\\sim 0$**\n",
    "\n",
    "A multi-class classification NN, with softmax output, is trained to output a score:\n",
    "\n",
    "$$ \\text{NN}_\\text{presel} = \\log \\left[\\frac{\\sum_S P_S (x)}{\\sum_B P_B(x)} \\right]$$\n",
    "\n",
    "where $P_c$ are the probability scores outputted from the softmax layer of the trained NN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['nsbi_common_utils.training'])\n",
    "from nsbi_common_utils.training import TrainEvaluatePreselNN\n",
    "\n",
    "num_classes = len(labels_dict)\n",
    "\n",
    "preselectionTraining = TrainEvaluatePreselNN(dataset_incl_nominal, \n",
    "                                            num_classes, \n",
    "                                            features, \n",
    "                                            features_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 00:34:23.708887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13377 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 00:34:26.740772: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-08-09 00:34:26.915586: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 91100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 - 9s - 11ms/step - accuracy: 0.7787 - loss: 3.4991e-07 - val_accuracy: 0.7904 - val_loss: 3.3566e-07 - learning_rate: 0.1000\n",
      "Epoch 2/50\n",
      "880/880 - 6s - 7ms/step - accuracy: 0.7961 - loss: 3.2722e-07 - val_accuracy: 0.8007 - val_loss: 3.1967e-07 - learning_rate: 0.1000\n",
      "Epoch 3/50\n",
      "880/880 - 6s - 7ms/step - accuracy: 0.8037 - loss: 3.1606e-07 - val_accuracy: 0.8053 - val_loss: 3.1337e-07 - learning_rate: 0.1000\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "if USE_SAVED_PRESEL_PREDICTIONS:\n",
    "\n",
    "    pred_NN_incl = np.load(f\"{PATH_TO_SAVED_DATA}pred_NN_incl.npy\")\n",
    "    presel_score = calculate_preselection_observable(pred_NN_incl, labels_dict, signal_processes, background_processes, pre_factor_dict = pre_factor_preselection_score)\n",
    "\n",
    "else:\n",
    "    if not USE_SAVED_MODEL_PRESEL:\n",
    "        preselectionTraining.train(test_size=0.2, \n",
    "                                   random_state=42, \n",
    "                                   path_to_save=PATH_PRESEL_MODEL,\n",
    "                                  batch_size=4096,\n",
    "                                  epochs=50, learning_rate=0.1)\n",
    "    \n",
    "    else:\n",
    "        preselectionTraining.get_trained_model(PATH_PRESEL_MODEL)\n",
    "\n",
    "    # Get predictions (softmax outputs)\n",
    "    pred_NN_incl = preselectionTraining.predict(dataset_incl_nominal)\n",
    "\n",
    "    presel_score = calculate_preselection_observable(pred_NN_incl, labels_dict, signal_processes, background_processes, pre_factor_dict = pre_factor_preselection_score)\n",
    "\n",
    "    np.save(f\"{PATH_TO_SAVED_DATA}presel_score.npy\", presel_score)\n",
    "    np.save(f\"{PATH_TO_SAVED_DATA}pred_NN_incl.npy\", pred_NN_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "min_pred = np.amin(presel_score)\n",
    "max_pred = np.amax(presel_score)\n",
    "\n",
    "bins = np.linspace(min_pred, max_pred, num=50)\n",
    "\n",
    "hist_NN_output = {}\n",
    "hist_NN_output_errs = {}\n",
    "\n",
    "for key in labels_dict: \n",
    "    hist_NN_output[key], _ = np.histogram(presel_score[train_labels==labels_dict[key]], \n",
    "                                          weights = weights[train_labels==labels_dict[key]], bins=bins)\n",
    "    \n",
    "    hist_NN_output_errs[key], _ = np.histogram(presel_score[train_labels==labels_dict[key]], \n",
    "                                          weights = weights[train_labels==labels_dict[key]]**2, bins=bins)\n",
    "\n",
    "\n",
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins=bins, \n",
    "             alpha=0.6, label=key, \n",
    "             density=True, linewidth=2.0, yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the cut\n",
    "===\n",
    "\n",
    "Make a selection cut for regions with $p_{ref} \\gg 0$ for performing the NSBI analysis. The remaining events - which by definition are background-dominated - can be used as a **Control Region** for data-driven background estimation, pre-unblinding validations, etc. \n",
    "\n",
    "Moreover, the preselections act as a tuning know for the tradeoff in selecting as many signal events as possible to go into the **Signal Region** (increasing sensitivity) and the feasibility of training accurate and precise NNs over a large phase space (need bigger models and more statistics). **The preselections can also weed out phase space regions with low background statistics to avoid poorly modelled regions.** \n",
    "\n",
    "Heres a first cut that you can optimize as much as you like to get the desired final results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Play around with these selections - decrease if estimators are unbiased but need more sensitivity and increase if the model is biased to reduce complexity\n",
    "preselection_cuts = {'upper': 4.5, 'lower': -1.}\n",
    "np.save(f\"{PATH_TO_SAVED_DATA}preselection_cuts.npy\", preselection_cuts)\n",
    "\n",
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = True, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = False, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal and Control Regions\n",
    "===\n",
    "\n",
    "The high signal over background phase space towards the right of the preselection cut shown above will be categorized as the **Signal Region** where the NSBI analysis is performed.\n",
    "\n",
    "The low signal phase space towards the left will be used as a **Control Region**, with typical uses such as background estimation, pre-unblinding data-MC checks, etc. In this phase space, we will use a binned summary observable like in any traditional analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importlib.reload(sys.modules['utils'])\n",
    "from utils import preselection_using_score\n",
    "\n",
    "\n",
    "dataset_incl_nominal['presel_score'] = presel_score\n",
    "\n",
    "channel_selections = {'CR': {'observable': 'presel_score', \n",
    "                             'lower_presel': -999, \n",
    "                             'upper_presel': preselection_cuts.get('lower'), \n",
    "                             'num_bins': 4},\n",
    "                      \n",
    "                      'SR_binned': {'observable': 'presel_score', \n",
    "                                    'lower_presel': preselection_cuts.get('upper'), \n",
    "                                    'upper_presel': -999,\n",
    "                                    'num_bins': 1},\n",
    "                      \n",
    "                      'SR': {'observable': None, \n",
    "                             'upper_presel': preselection_cuts.get('upper'), \n",
    "                             'lower_presel': preselection_cuts.get('lower')}}\n",
    "\n",
    "dataset_channels = preselection_using_score(dataset_incl_nominal, channel_selections)\n",
    "\n",
    "del dataset_incl_nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsbi_env_newish",
   "language": "python",
   "name": "nsbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
