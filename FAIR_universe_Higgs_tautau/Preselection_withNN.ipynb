{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsandesara_umass_edu/NSBI-workflow-tutorial/src/nsbi_common_utils/plotting.py:11: FutureWarning: ``set_style`` is deprecated: Naming convention is changing to match mpl. Use ``mplhep.style.use()``.\n",
      "  hep.set_style(\"ATLAS\")\n",
      "2025-10-24 15:53:44.019952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-24 15:53:44.041073: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-24 15:53:44.047336: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-24 15:53:44.063014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pathlib, importlib\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load the package and modules for training and plotting\n",
    "import nsbi_common_utils\n",
    "from nsbi_common_utils import plotting, training, datasets, configuration\n",
    "from nsbi_common_utils.training import TrainEvaluate_NN, TrainEvaluatePreselNN\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_jit(False)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "from utils import preselection_using_score, calculate_preselection_observable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "hep.style.use(hep.style.ATLAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODOs\n",
    "## define mutable vs immutable information\n",
    "\n",
    "config = nsbi_common_utils.configuration.ConfigManager(file_path_string = './config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['nsbi_common_utils.datasets'])\n",
    "from nsbi_common_utils import datasets\n",
    "\n",
    "Datasets = nsbi_common_utils.datasets.datasets(config_path = './config.yml',\n",
    "                                                branches_to_load = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of labels to processes\n",
    "train_label_sample_dict = {\"htautau\"        : 0,\n",
    "                            \"ttbar\"         : 1,\n",
    "                            \"ztautau\"       : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_incl_dict = Datasets.load_datasets_from_config(load_systematics = True)\n",
    "\n",
    "dataset_incl_nominal = dataset_incl_dict[\"Nominal\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_incl_nominal_training = Datasets.merge_dataframe_dict_for_training(dataset_incl_nominal, \n",
    "                                                                            train_label_sample_dict,\n",
    "                                                                            samples_to_merge = dataset_incl_nominal.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Preselection NN\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choice of reference sample**\n",
    "\n",
    "The density ratios need to be trained on phase space regions with support for the reference hypothesis $p_{ref}(x) > 0$.\n",
    "\n",
    "To ensure this, we make a selection that selects events in the phase space regions with $p_{ref}(x) > 0$, or $p_c(x) \\gg p_{ref}(x)$, and only perform the NSBI fit in this selected analysis region. **A natural choice for the reference hypothesis is then the signal-rich hypotheses**. This is referred to in the ATLAS publications as the Search-Oriented Mixture Models approach: \n",
    "\n",
    "$$p_{ref}(x) = \\frac{1}{\\sum_S \\nu_S} \\sum_S \\frac{d\\sigma_S}{dx} = \\frac{1}{\\nu_{H \\to \\tau\\tau}} \\frac{d\\sigma_{H \\to \\tau\\tau}}{dx}$$\n",
    "\n",
    "where the sum runs over all signal hypothesis in the model and the second equality is due to the sole signal hypothesis in our toy model, $pp \\to {t\\bar{t}}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting out regions with $p_{ref}\\sim 0$**\n",
    "\n",
    "A multi-class classification NN, with softmax output, is trained to output a score:\n",
    "\n",
    "$$ \\text{NN}_\\text{presel} = \\log \\left[\\frac{\\sum_S P_S (x)}{\\sum_B P_B(x)} \\right]$$\n",
    "\n",
    "where $P_c$ are the probability scores outputted from the softmax layer of the trained NN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DER_mass_transverse_met_lep', 'log_DER_mass_vis', 'log_DER_pt_h', 'DER_deltar_had_lep', 'log_DER_pt_tot', 'log_DER_sum_pt', 'DER_pt_ratio_lep_had', 'DER_met_phi_centrality']\n"
     ]
    }
   ],
   "source": [
    "features, features_scaling = config.get_training_features()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 16:04:28.338350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9615 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 16:04:31.402970: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-24 16:04:31.517522: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 - 12s - 14ms/step - accuracy: 0.7785 - loss: 3.4931e-07 - val_accuracy: 0.7900 - val_loss: 3.3400e-07 - learning_rate: 0.1000\n",
      "Epoch 2/50\n",
      "880/880 - 7s - 8ms/step - accuracy: 0.7948 - loss: 3.2799e-07 - val_accuracy: 0.7988 - val_loss: 3.2221e-07 - learning_rate: 0.1000\n",
      "Epoch 3/50\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sys.modules['nsbi_common_utils.training'])\n",
    "from nsbi_common_utils.training import TrainEvaluatePreselNN\n",
    "\n",
    "PATH_PRESEL_MODEL = './saved_datasets_new/preselection_model/'\n",
    "\n",
    "# If the preselection NN has already been trained and saved, load from the saved model\n",
    "USE_SAVED_MODEL_PRESEL = False\n",
    "\n",
    "\n",
    "preselectionTraining = TrainEvaluatePreselNN(dataset_incl_nominal_training, \n",
    "                                            features, \n",
    "                                            features_scaling)\n",
    "\n",
    "if not USE_SAVED_MODEL_PRESEL:\n",
    "    preselectionTraining.train(test_size=0.2, \n",
    "                                random_state=42, \n",
    "                                path_to_save=PATH_PRESEL_MODEL,\n",
    "                                batch_size=4096,\n",
    "                                epochs=50, \n",
    "                                learning_rate=0.1)\n",
    "\n",
    "else:\n",
    "    preselectionTraining.assign_trained_model(PATH_PRESEL_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region_name, dataset_sample_dict in dataset_incl_dict.items():\n",
    "\n",
    "    for sample_name, dataset in dataset_sample_dict.items():\n",
    "\n",
    "        # Get predictions (softmax outputs)\n",
    "        pred_NN_incl = preselectionTraining.predict(dataset)\n",
    "        print(pred_NN_incl)\n",
    "        presel_score = calculate_preselection_observable(pred_NN_incl, \n",
    "                                                        train_label_sample_dict, \n",
    "                                                        signal_processes       = ['htautau'], \n",
    "                                                        background_processes   = ['ttbar', 'ztautau'], \n",
    "                                                        pre_factor_dict        = {'htautau': 1.0, 'ttbar': 1.0, 'ztautau': 1.0})\n",
    "\n",
    "        dataset_incl_dict[region_name][sample_name]['presel_score'] = presel_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets.add_appended_branches(['presel_score'])\n",
    "Datasets.save_datasets(dataset_incl_dict, save_systematics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pred = np.amin(presel_score)\n",
    "max_pred = np.amax(presel_score)\n",
    "\n",
    "bins = np.linspace(min_pred, max_pred, num=50)\n",
    "\n",
    "hist_NN_output          = {}\n",
    "hist_NN_output_errs     = {}\n",
    "\n",
    "presel_score_arr        = {}\n",
    "\n",
    "for sample_name, sample_dataset in dataset_incl_dict[\"Nominal\"].items():\n",
    "\n",
    "    presel_score_arr    = sample_dataset['presel_score']\n",
    "    weights             = sample_dataset['weights']\n",
    "\n",
    "    hist_NN_output[sample_name], _          = np.histogram(presel_score_arr, weights = weights,     bins=bins)\n",
    "    \n",
    "    hist_NN_output_errs[sample_name], _     = np.histogram(presel_score_arr, weights = weights**2,  bins=bins)\n",
    "\n",
    "    hep.histplot(hist_NN_output[sample_name], bins=bins, \n",
    "             alpha=0.6, label=sample_name, \n",
    "             density=True, linewidth=2.0, yerr = np.sqrt(hist_NN_output_errs[sample_name]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the cut\n",
    "===\n",
    "\n",
    "Make a selection cut for regions with $p_{ref} \\gg 0$ for performing the NSBI analysis. The remaining events - which by definition are background-dominated - can be used as a **Control Region** for data-driven background estimation, pre-unblinding validations, etc. \n",
    "\n",
    "Moreover, the preselections act as a tuning know for the tradeoff in selecting as many signal events as possible to go into the **Signal Region** (increasing sensitivity) and the feasibility of training accurate and precise NNs over a large phase space (need bigger models and more statistics). **The preselections can also weed out phase space regions with low background statistics to avoid poorly modelled regions.** \n",
    "\n",
    "Heres a first cut that you can optimize as much as you like to get the desired final results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with these selections - decrease if estimators are unbiased but need more sensitivity and increase if the model is biased to reduce complexity\n",
    "preselection_cuts = {'upper': 4.5, 'lower': -1.}\n",
    "\n",
    "## Convert to an object that takes inputs - better for dynamic changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sample_name, sample_dataset in dataset_incl_dict[\"Nominal\"].items():\n",
    "\n",
    "    hep.histplot(hist_NN_output[sample_name], bins=bins, \n",
    "             alpha=0.6, label=sample_name, \n",
    "             density=True, linewidth=2.0, yerr = np.sqrt(hist_NN_output_errs[sample_name]))\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_label_sample_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = True, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_label_sample_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = False, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal and Control Regions\n",
    "===\n",
    "\n",
    "The high signal over background phase space towards the right of the preselection cut shown above will be categorized as the **Signal Region** where the NSBI analysis is performed.\n",
    "\n",
    "The low signal phase space towards the left will be used as a **Control Region**, with typical uses such as background estimation, pre-unblinding data-MC checks, etc. In this phase space, we will use a binned summary observable like in any traditional analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pixi: nsbi-env-gpu-new-higgs)",
   "language": "python",
   "name": "nsbi-env-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
