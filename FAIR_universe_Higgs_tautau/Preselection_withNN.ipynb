{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/nsbi_common_utils/plotting.py:11: FutureWarning: ``set_style`` is deprecated: Naming convention is changing to match mpl. Use ``mplhep.style.use()``.\n",
      "  hep.set_style(\"ATLAS\")\n",
      "2025-08-08 19:09:29.026914: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 19:09:29.876201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754680170.158881  362940 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754680170.254788  362940 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-08 19:09:31.023289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pathlib, importlib\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load the package and modules for training and plotting\n",
    "import nsbi_common_utils\n",
    "from nsbi_common_utils import plotting, training\n",
    "from nsbi_common_utils.training import TrainEvaluate_NN, TrainEvaluatePreselNN\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "from utils import preselection_using_score, calculate_preselection_observable\n",
    "\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "hep.style.use(hep.style.ATLAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PATH_PREFIX = config[\"PATH_PREFIX\"]\n",
    "PATH_TO_SAVED_DATA = config[\"PATH_SAVED_DATA\"]\n",
    "\n",
    "PATH_PRESEL_MODEL = PATH_TO_SAVED_DATA + 'preselection_model/'\n",
    "\n",
    "config.update(\n",
    "    {\n",
    "        \"PATH_PRESEL_MODEL\": PATH_PRESEL_MODEL\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau']\n",
      "['ttbar', 'ztautau']\n"
     ]
    }
   ],
   "source": [
    "# Get the dictionary of labels to processes\n",
    "labels_dict = config[\"PROCESS_TO_INT_LABELS_DICT\"]\n",
    "\n",
    "# Signal processes in the model\n",
    "signal_processes = config[\"SIGNAL_PROCESSES\"]\n",
    "\n",
    "# Background processes in the model\n",
    "background_processes = config[\"BACKGROUND_PROCESSES\"]\n",
    "\n",
    "print(signal_processes)\n",
    "print(background_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If the preselection NN has already been trained and saved, load from the saved model\n",
    "USE_SAVED_MODEL_PRESEL = False\n",
    "\n",
    "# If the preselection NN has already been trained and evaluated, load the numpy array of predictions\n",
    "USE_SAVED_PRESEL_PREDICTIONS = False\n",
    "\n",
    "# Input features for training\n",
    "features = config[\"TRAINING_FEATURES\"]\n",
    "\n",
    "# Subset of the features to standardize before training\n",
    "features_scaling = config[\"TRAINING_FEATURES_TO_SCALE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the nominal dataset saved from the pre-processing notebook\n",
    "\n",
    "path_to_nominal_dataframe = config[\"PATH_TO_nominal_DATA\"]\n",
    "dataset_incl_nominal = pd.read_hdf(path_to_nominal_dataframe, key=\"dataset\", mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MC/data weights and training labels identifying different processes\n",
    "weights         = dataset_incl_nominal[\"weights\"].to_numpy()\n",
    "train_labels    = dataset_incl_nominal[\"train_labels\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the training weights - only discriminating shapes\n",
    "weights_normed  = weights.copy()\n",
    "\n",
    "for key in labels_dict:\n",
    "\n",
    "    weights_normed[train_labels==labels_dict[key]] /= weights[train_labels==labels_dict[key]].sum()\n",
    "\n",
    "dataset_incl_nominal['weights_normed'] = weights_normed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Preselection NN\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choice of reference sample**\n",
    "\n",
    "The density ratios need to be trained on phase space regions with support for the reference hypothesis $p_{ref}(x) > 0$.\n",
    "\n",
    "To ensure this, we make a selection that selects events in the phase space regions with $p_{ref}(x) > 0$, or $p_c(x) \\gg p_{ref}(x)$, and only perform the NSBI fit in this selected analysis region. **A natural choice for the reference hypothesis is then the signal-rich hypotheses**. This is referred to in the ATLAS publications as the Search-Oriented Mixture Models approach: \n",
    "\n",
    "$$p_{ref}(x) = \\frac{1}{\\sum_S \\nu_S} \\sum_S \\frac{d\\sigma_S}{dx} = \\frac{1}{\\nu_{H \\to \\tau\\tau}} \\frac{d\\sigma_{H \\to \\tau\\tau}}{dx}$$\n",
    "\n",
    "where the sum runs over all signal hypothesis in the model and the second equality is due to the sole signal hypothesis in our toy model, $pp \\to {t\\bar{t}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau']\n"
     ]
    }
   ],
   "source": [
    "# What are the signal processes in the user-provided model?\n",
    "print(signal_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['htautau', 'ttbar']\n"
     ]
    }
   ],
   "source": [
    "# The reference hypothesis is chosen as the sum of signal hypothesis\n",
    "ref_processes = config[\"REFERENCE_PROCESSES\"]\n",
    "print(ref_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting out regions with $p_{ref}\\sim 0$**\n",
    "\n",
    "A multi-class classification NN, with softmax output, is trained to output a score:\n",
    "\n",
    "$$ \\text{NN}_\\text{presel} = \\log \\left[\\frac{\\sum_S P_S (x)}{\\sum_B P_B(x)} \\right]$$\n",
    "\n",
    "where $P_c$ are the probability scores outputted from the softmax layer of the trained NN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['nsbi_common_utils.training'])\n",
    "from nsbi_common_utils.training import TrainEvaluatePreselNN\n",
    "\n",
    "num_classes = len(labels_dict)\n",
    "\n",
    "preselectionTraining = TrainEvaluatePreselNN(dataset_incl_nominal, \n",
    "                                            num_classes, \n",
    "                                            features, \n",
    "                                            features_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754682964.177106  362940 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13377 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1754682964.967370  373648 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "W0000 00:00:1754682965.024968  373650 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.025842  373653 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.026713  373651 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.027630  373658 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.028547  373656 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.029427  373659 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.030342  373652 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.031223  373654 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.032100  373657 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.033017  373649 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.033895  373648 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.034764  373655 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1754682965.041124  373650 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754682966.433520  373525 service.cc:148] XLA service 0x738c080078c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754682966.436800  373525 service.cc:156]   StreamExecutor device (0): NVIDIA A16, Compute Capability 8.6\n",
      "2025-08-08 19:56:06.541030: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1754682966.680128  373525 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "2025-08-08 19:56:06.782028: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : NOT_FOUND: Couldn't find a suitable version of ptxas. The following locations were considered: ./cuda_sdk_lib/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/jupyterlab/unity-jupyterlab4.4.3/bin/ptxas, /modules/apps/matlab/r2025a/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/miniforge3/24.7.1/condabin/ptxas, /modules/user-resources/bin/ptxas, /usr/local/sbin/ptxas, /usr/local/bin/ptxas, /usr/sbin/ptxas, /usr/bin/ptxas, /sbin/ptxas, /bin/ptxas, /usr/games/ptxas, /usr/local/games/ptxas, /snap/bin/ptxas, ipykernel_launcher.runfiles/cuda_nvcc/bin/ptxas, ipykern/cuda_nvcc/bin/ptxas, bin/ptxas, /usr/local/cuda/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda/bin/ptxas\n",
      "2025-08-08 19:56:06.782086: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: NOT_FOUND: Couldn't find a suitable version of ptxas. The following locations were considered: ./cuda_sdk_lib/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/jupyterlab/unity-jupyterlab4.4.3/bin/ptxas, /modules/apps/matlab/r2025a/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/miniforge3/24.7.1/condabin/ptxas, /modules/user-resources/bin/ptxas, /usr/local/sbin/ptxas, /usr/local/bin/ptxas, /usr/sbin/ptxas, /usr/bin/ptxas, /sbin/ptxas, /bin/ptxas, /usr/games/ptxas, /usr/local/games/ptxas, /snap/bin/ptxas, ipykernel_launcher.runfiles/cuda_nvcc/bin/ptxas, ipykern/cuda_nvcc/bin/ptxas, bin/ptxas, /usr/local/cuda/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda/bin/ptxas\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_362940/3396085713.py\", line 8, in <module>\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/nsbi_common_utils/training.py\", line 107, in train\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nCouldn't find a suitable version of ptxas. The following locations were considered: ./cuda_sdk_lib/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/jupyterlab/unity-jupyterlab4.4.3/bin/ptxas, /modules/apps/matlab/r2025a/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/miniforge3/24.7.1/condabin/ptxas, /modules/user-resources/bin/ptxas, /usr/local/sbin/ptxas, /usr/local/bin/ptxas, /usr/sbin/ptxas, /usr/bin/ptxas, /sbin/ptxas, /bin/ptxas, /usr/games/ptxas, /usr/local/games/ptxas, /snap/bin/ptxas, ipykernel_launcher.runfiles/cuda_nvcc/bin/ptxas, ipykern/cuda_nvcc/bin/ptxas, bin/ptxas, /usr/local/cuda/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda/bin/ptxas\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_1883]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m USE_SAVED_MODEL_PRESEL:\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mpreselectionTraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpath_to_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATH_PRESEL_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         preselectionTraining\u001b[38;5;241m.\u001b[39mget_trained_model(PATH_PRESEL_MODEL)\n",
      "File \u001b[0;32m~/.conda/envs/NSBI_env/lib/python3.11/site-packages/nsbi_common_utils/training.py:107\u001b[0m, in \u001b[0;36mTrainEvaluatePreselNN.train\u001b[0;34m(self, test_size, random_state, path_to_save, epochs, batch_size, verbose, learning_rate)\u001b[0m\n\u001b[1;32m    103\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39mcallback_factor,\n\u001b[1;32m    104\u001b[0m                                 patience\u001b[38;5;241m=\u001b[39mcallback_patience, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000000001\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Train the model with sample weights\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Save the trained model if user provides with a path\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_362940/3396085713.py\", line 8, in <module>\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/nsbi_common_utils/training.py\", line 107, in train\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nCouldn't find a suitable version of ptxas. The following locations were considered: ./cuda_sdk_lib/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/jupyterlab/unity-jupyterlab4.4.3/bin/ptxas, /modules/apps/matlab/r2025a/bin/ptxas, /modules/opt/linux-ubuntu24.04-x86_64/miniforge3/24.7.1/condabin/ptxas, /modules/user-resources/bin/ptxas, /usr/local/sbin/ptxas, /usr/local/bin/ptxas, /usr/sbin/ptxas, /usr/bin/ptxas, /sbin/ptxas, /bin/ptxas, /usr/games/ptxas, /usr/local/games/ptxas, /snap/bin/ptxas, ipykernel_launcher.runfiles/cuda_nvcc/bin/ptxas, ipykern/cuda_nvcc/bin/ptxas, bin/ptxas, /usr/local/cuda/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc/bin/ptxas, /home/jsandesara_umass_edu/.conda/envs/NSBI_env/lib/python3.11/site-packages/tensorflow/python/platform/../../cuda/bin/ptxas\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_1883]"
     ]
    }
   ],
   "source": [
    "if USE_SAVED_PRESEL_PREDICTIONS:\n",
    "\n",
    "    pred_NN_incl = np.load(f\"{PATH_TO_SAVED_DATA}pred_NN_incl.npy\")\n",
    "    presel_score = calculate_preselection_observable(pred_NN_incl, labels_dict, signal_processes, background_processes, pre_factor_dict = pre_factor_preselection_score)\n",
    "\n",
    "else:\n",
    "    if not USE_SAVED_MODEL_PRESEL:\n",
    "        preselectionTraining.train(test_size=0.2, \n",
    "                                   random_state=42, \n",
    "                                   path_to_save=PATH_PRESEL_MODEL,\n",
    "                                  batch_size=4096,\n",
    "                                  epochs=50, learning_rate=0.1)\n",
    "    \n",
    "    else:\n",
    "        preselectionTraining.get_trained_model(PATH_PRESEL_MODEL)\n",
    "\n",
    "    # Get predictions (softmax outputs)\n",
    "    pred_NN_incl = preselectionTraining.predict(dataset_incl_nominal)\n",
    "\n",
    "    presel_score = calculate_preselection_observable(pred_NN_incl, labels_dict, signal_processes, background_processes, pre_factor_dict = pre_factor_preselection_score)\n",
    "\n",
    "    np.save(f\"{PATH_TO_SAVED_DATA}presel_score.npy\", presel_score)\n",
    "    np.save(f\"{PATH_TO_SAVED_DATA}pred_NN_incl.npy\", pred_NN_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "min_pred = np.amin(presel_score)\n",
    "max_pred = np.amax(presel_score)\n",
    "\n",
    "bins = np.linspace(min_pred, max_pred, num=50)\n",
    "\n",
    "hist_NN_output = {}\n",
    "hist_NN_output_errs = {}\n",
    "\n",
    "for key in labels_dict: \n",
    "    hist_NN_output[key], _ = np.histogram(presel_score[train_labels==labels_dict[key]], \n",
    "                                          weights = weights[train_labels==labels_dict[key]], bins=bins)\n",
    "    \n",
    "    hist_NN_output_errs[key], _ = np.histogram(presel_score[train_labels==labels_dict[key]], \n",
    "                                          weights = weights[train_labels==labels_dict[key]]**2, bins=bins)\n",
    "\n",
    "\n",
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins=bins, \n",
    "             alpha=0.6, label=key, \n",
    "             density=True, linewidth=2.0, yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the cut\n",
    "===\n",
    "\n",
    "Make a selection cut for regions with $p_{ref} \\gg 0$ for performing the NSBI analysis. The remaining events - which by definition are background-dominated - can be used as a **Control Region** for data-driven background estimation, pre-unblinding validations, etc. \n",
    "\n",
    "Moreover, the preselections act as a tuning know for the tradeoff in selecting as many signal events as possible to go into the **Signal Region** (increasing sensitivity) and the feasibility of training accurate and precise NNs over a large phase space (need bigger models and more statistics). **The preselections can also weed out phase space regions with low background statistics to avoid poorly modelled regions.** \n",
    "\n",
    "Heres a first cut that you can optimize as much as you like to get the desired final results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Play around with these selections - decrease if estimators are unbiased but need more sensitivity and increase if the model is biased to reduce complexity\n",
    "preselection_cuts = {'upper': 4.5, 'lower': -1.}\n",
    "np.save(f\"{PATH_TO_SAVED_DATA}preselection_cuts.npy\", preselection_cuts)\n",
    "\n",
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = True, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for key in labels_dict:  \n",
    "    hep.histplot(hist_NN_output[key], bins = bins, \n",
    "             alpha = 0.6, label = key, \n",
    "             density = False, linewidth = 2.0, \n",
    "                 yerr = np.sqrt(hist_NN_output_errs[key]))\n",
    "\n",
    "plt.xlabel(\"Preselection Score\", size=18)\n",
    "\n",
    "for key in preselection_cuts:\n",
    "    if preselection_cuts[key] != -999:\n",
    "        plt.axvline(preselection_cuts[key], ymax=0.9, linestyle='--', label=f'preselection cut {key} = {preselection_cuts[key]}')\n",
    "\n",
    "plt.ylabel(\"Density\", size=18)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal and Control Regions\n",
    "===\n",
    "\n",
    "The high signal over background phase space towards the right of the preselection cut shown above will be categorized as the **Signal Region** where the NSBI analysis is performed.\n",
    "\n",
    "The low signal phase space towards the left will be used as a **Control Region**, with typical uses such as background estimation, pre-unblinding data-MC checks, etc. In this phase space, we will use a binned summary observable like in any traditional analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importlib.reload(sys.modules['utils'])\n",
    "from utils import preselection_using_score\n",
    "\n",
    "\n",
    "dataset_incl_nominal['presel_score'] = presel_score\n",
    "\n",
    "channel_selections = {'CR': {'observable': 'presel_score', \n",
    "                             'lower_presel': -999, \n",
    "                             'upper_presel': preselection_cuts.get('lower'), \n",
    "                             'num_bins': 4},\n",
    "                      \n",
    "                      'SR_binned': {'observable': 'presel_score', \n",
    "                                    'lower_presel': preselection_cuts.get('upper'), \n",
    "                                    'upper_presel': -999,\n",
    "                                    'num_bins': 1},\n",
    "                      \n",
    "                      'SR': {'observable': None, \n",
    "                             'upper_presel': preselection_cuts.get('upper'), \n",
    "                             'lower_presel': preselection_cuts.get('lower')}}\n",
    "\n",
    "dataset_channels = preselection_using_score(dataset_incl_nominal, channel_selections)\n",
    "\n",
    "del dataset_incl_nominal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSBI",
   "language": "python",
   "name": "nsbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
