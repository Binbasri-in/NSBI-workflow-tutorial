{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37133e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/NSBI-workflow-tutorial/FAIR_universe_Higgs_tautau/saved_datasets/dataset_nominal.root'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     17\u001b[39m branches_to_load = features + [\u001b[33m'\u001b[39m\u001b[33mpresel_score\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m Datasets = nsbi_common_utils.datasets.datasets(config_path = \u001b[33m'\u001b[39m\u001b[33m./config.yml\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     20\u001b[39m                                                 branches_to_load =  branches_to_load)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m dataset_incl_dict      = \u001b[43mDatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_datasets_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_systematics\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m dataset_incl_nominal   = dataset_incl_dict[\u001b[33m\"\u001b[39m\u001b[33mNominal\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m     26\u001b[39m dataset_SR_nominal     = Datasets.filter_region_dataset(dataset_incl_nominal,\n\u001b[32m     27\u001b[39m                                                        region = \u001b[33m\"\u001b[39m\u001b[33mSR\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/NSBI-workflow-tutorial/src/nsbi_common_utils/datasets.py:67\u001b[39m, in \u001b[36mdatasets.load_datasets_from_config\u001b[39m\u001b[34m(self, load_systematics)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight_branch[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m branches_to_load:\n\u001b[32m     65\u001b[39m     branches_to_load += weight_branch\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m dict_datasets[\u001b[33m\"\u001b[39m\u001b[33mNominal\u001b[39m\u001b[33m\"\u001b[39m][sample_name] = \u001b[43mload_dataframe_from_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_root_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m                                                                \u001b[49m\u001b[43mtree_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m                                                                \u001b[49m\u001b[43mbranches_to_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m dict_datasets[\u001b[33m\"\u001b[39m\u001b[33mNominal\u001b[39m\u001b[33m\"\u001b[39m][sample_name][\u001b[33m\"\u001b[39m\u001b[33msample_name\u001b[39m\u001b[33m\"\u001b[39m] = sample_name\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mWeight\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dict_sample.keys():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/NSBI-workflow-tutorial/src/nsbi_common_utils/datasets.py:329\u001b[39m, in \u001b[36mload_dataframe_from_root\u001b[39m\u001b[34m(path_to_load, tree_name, branches_to_load)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_dataframe_from_root\u001b[39m(path_to_load      : \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    317\u001b[39m                            tree_name         : \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    318\u001b[39m                            branches_to_load  : \u001b[38;5;28mlist\u001b[39m) -> pd.DataFrame:\n\u001b[32m    319\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    Utility: read selected branches from a ROOT TTree into a DataFrame.\u001b[39;00m\n\u001b[32m    321\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m \u001b[33;03m        pd.DataFrame containing the requested branches.\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43muproot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_to_load\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtree_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tree:\n\u001b[32m    330\u001b[39m             dataframe = tree.arrays(branches_to_load, library=\u001b[33m\"\u001b[39m\u001b[33mpd\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/uproot/reading.py:142\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mseek\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m ):\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a string, pathlib.Path, an object with \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mseek\u001b[39m\u001b[33m'\u001b[39m\u001b[33m methods, or a length-1 dict of \u001b[39m\u001b[33m{\u001b[39m\u001b[33mfile_path: object_path}, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m file = \u001b[43mReadOnlyFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43marray_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43marray_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file.root_directory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/uproot/reading.py:573\u001b[39m, in \u001b[36mReadOnlyFile.__init__\u001b[39m\u001b[34m(self, file_path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size\u001b[39m\u001b[33m\"\u001b[39m] < _file_header_fields_big.size:\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is not enough to read the TFile header (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    568\u001b[39m             \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    569\u001b[39m             _file_header_fields_big.size,\n\u001b[32m    570\u001b[39m         )\n\u001b[32m    571\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28mself\u001b[39m._begin_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_source\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbegin_chunk_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.detach_memmap()\n\u001b[32m    577\u001b[39m \u001b[38;5;28mself\u001b[39m.hook_before_interpret()\n\u001b[32m    579\u001b[39m (\n\u001b[32m    580\u001b[39m     magic,\n\u001b[32m    581\u001b[39m     \u001b[38;5;28mself\u001b[39m._fVersion,\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m     \u001b[38;5;28mself\u001b[39m._begin_chunk, _file_header_fields_small, {}\n\u001b[32m    596\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/uproot/source/fsspec.py:117\u001b[39m, in \u001b[36mFSSpecSource.chunk\u001b[39m\u001b[34m(self, start, stop)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m._num_requested_chunks += \u001b[32m1\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._num_requested_bytes += stop - start\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m future = uproot.source.futures.TrivialFuture(data)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m uproot.source.chunk.Chunk(\u001b[38;5;28mself\u001b[39m, start, stop, future)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/fsspec/spec.py:773\u001b[39m, in \u001b[36mAbstractFileSystem.cat_file\u001b[39m\u001b[34m(self, path, start, end, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the content of a file\u001b[39;00m\n\u001b[32m    762\u001b[39m \n\u001b[32m    763\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m \u001b[33;03mkwargs: passed to ``open()``.\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;66;03m# explicitly set buffering off?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    775\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m start >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/fsspec/spec.py:1303\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1302\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1312\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/fsspec/implementations/local.py:191\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/fsspec/implementations/local.py:355\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    354\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/fsspec/implementations/local.py:360\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    362\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/NSBI-workflow-tutorial/FAIR_universe_Higgs_tautau/saved_datasets/dataset_nominal.root'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "# load local nsbi_common_utils package in home directory\n",
    "sys.path.append('/workspaces/NSBI-workflow-tutorial/src/')\n",
    "import nsbi_common_utils.configuration\n",
    "import nsbi_common_utils.datasets\n",
    "\n",
    "\n",
    "# Load the config file to get metadata like training features\n",
    "config = nsbi_common_utils.configuration.ConfigManager(file_path_string = './config.yml')\n",
    "\n",
    "# Input features for training\n",
    "features, features_scaling = config.get_training_features()\n",
    "\n",
    "\n",
    "branches_to_load = features + ['presel_score']\n",
    "\n",
    "Datasets = nsbi_common_utils.datasets.datasets(config_path = './config.yml',\n",
    "                                                branches_to_load =  branches_to_load)\n",
    "\n",
    "dataset_incl_dict      = Datasets.load_datasets_from_config(load_systematics = False)\n",
    "\n",
    "dataset_incl_nominal   = dataset_incl_dict[\"Nominal\"].copy()\n",
    "\n",
    "dataset_SR_nominal     = Datasets.filter_region_dataset(dataset_incl_nominal,\n",
    "                                                       region = \"SR\")\n",
    "\n",
    "# Define the processes that make up the mixture model formula for density ratio estimation\n",
    "\n",
    "PATH_TO_SAVED_DATA = './saved_datasets/'\n",
    "TRAINING_OUTPUT_PATH = f'{PATH_TO_SAVED_DATA}output_training_nominal/'\n",
    "\n",
    "# Signal processes in the model\n",
    "basis_processes = config.get_basis_samples()\n",
    "print(basis_processes)\n",
    "\n",
    "ref_processes = config.get_reference_samples()\n",
    "print(ref_processes)\n",
    "\n",
    "\n",
    "##### Training the density ratio estimator model #####\n",
    "importlib.reload(sys.modules['nsbi_common_utils.training'])\n",
    "from nsbi_common_utils.training import TrainEvaluate_NN\n",
    "\n",
    "ref_train_label_sample_dict = {**{ref: 0 for ref in ref_processes}}\n",
    "\n",
    "dataset_ref     = Datasets.merge_dataframe_dict_for_training(dataset_SR_nominal, \n",
    "                                                            ref_train_label_sample_dict, \n",
    "                                                            samples_to_merge = ref_processes)\n",
    "\n",
    "NN_training_mix_model = {}\n",
    "\n",
    "use_log_loss = False\n",
    "\n",
    "# DELETE_EXISTING_MODELS = True\n",
    "DELETE_EXISTING_MODELS = False\n",
    "\n",
    "path_to_ratios = {}\n",
    "path_to_figures = {}\n",
    "path_to_models = {}\n",
    "\n",
    "for process_type in basis_processes:\n",
    "\n",
    "    # Get the dictionary of labels to processes\n",
    "    _train_label_sample_dict = {process_type        : 1}\n",
    "\n",
    "    dataset_num     = Datasets.merge_dataframe_dict_for_training(dataset_SR_nominal, \n",
    "                                                                _train_label_sample_dict, \n",
    "                                                                samples_to_merge = [process_type])\n",
    "\n",
    "    # Build a training dataset for the training of p_<process_type>/p_<ref_processes> density ratio\n",
    "    dataset_mix_model = pd.concat([dataset_num, dataset_ref])\n",
    "\n",
    "    # Save paths\n",
    "    output_name                     = f'{process_type}'\n",
    "    output_dir                      = f'{TRAINING_OUTPUT_PATH}general_output_{process_type}'\n",
    "    path_to_ratios[process_type]    = f'{TRAINING_OUTPUT_PATH}output_ratios_{process_type}/'\n",
    "    path_to_figures[process_type]   = f'{TRAINING_OUTPUT_PATH}output_figures_{process_type}/'\n",
    "    path_to_models[process_type]    = f'{TRAINING_OUTPUT_PATH}output_model_params_{process_type}/'\n",
    "\n",
    "    NN_training_mix_model[process_type] = TrainEvaluate_NN(dataset_mix_model, \n",
    "                                                           dataset_mix_model['weights_normed'].to_numpy(),\n",
    "                                                           dataset_mix_model['train_labels'].to_numpy(),\n",
    "                                                           features, \n",
    "                                                           features_scaling, \n",
    "                                                           [process_type, 'ref'], \n",
    "                                                            output_dir, output_name, \n",
    "                                                            path_to_figures=path_to_figures[process_type],\n",
    "                                                            path_to_ratios=path_to_ratios[process_type], \n",
    "                                                            path_to_models=path_to_models[process_type],\n",
    "                                                            use_log_loss = use_log_loss,\n",
    "                                                            delete_existing_models = DELETE_EXISTING_MODELS)\n",
    "\n",
    "\n",
    "    del dataset_mix_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bff23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
