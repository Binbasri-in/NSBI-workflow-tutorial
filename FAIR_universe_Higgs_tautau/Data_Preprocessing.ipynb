{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path_prefix = '/home/jaySandesara/NSBI_workflow_tutorial/FAIR_universe_Higgs_tautau/'\n",
    "\n",
    "import os\n",
    "os.chdir(f\"{path_prefix}\")\n",
    "\n",
    "from HiggsML.datasets import download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 17:09:12,295 - HiggsML.datasets     - INFO     - Handling as URL: https://zenodo.org/records/15131565/files/FAIR_Universe_HiggsML_data.zip\n",
      "2025-05-31 17:09:12,296 - HiggsML.datasets     - INFO     - Current working directory: /data/jaySandesara/NSBI_workflow_tutorial/FAIR_universe_Higgs_tautau\n",
      "2025-05-31 17:09:12,384 - HiggsML.datasets     - INFO     - Total rows: 220099101\n",
      "2025-05-31 17:09:12,384 - HiggsML.datasets     - INFO     - Test size: 66029730\n"
     ]
    }
   ],
   "source": [
    "data = download_dataset(\"https://zenodo.org/records/15131565/files/FAIR_Universe_HiggsML_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an integer with each of the processes (same as the dictionary used to load)\n",
    "labels_dict = {\"htautau\": 0,\n",
    "              \"ztautau\":1,\n",
    "              \"ttbar\":2,\n",
    "              \"diboson\":3}\n",
    "\n",
    "np.save(f\"{saved_data}labels_dictionary.npy\", labels_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 17:09:19,217 - HiggsML.datasets     - INFO     - Selected train size: 7703468\n",
      "2025-05-31 17:11:59,890 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data.load_train_set(train_size=0.05)\n",
    "df_training = data.get_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_had_pt', 'PRI_had_eta',\n",
       "       'PRI_had_phi', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta',\n",
       "       'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n",
       "       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_n_jets',\n",
       "       'PRI_jet_all_pt', 'PRI_met', 'PRI_met_phi', 'weights',\n",
       "       'detailed_labels', 'labels', 'DER_mass_transverse_met_lep',\n",
       "       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_had_lep', 'DER_pt_tot', 'DER_sum_pt',\n",
       "       'DER_pt_ratio_lep_had', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = '/home/jaySandesara/NSBI_workflow_tutorial/FAIR_universe_Higgs_tautau/'\n",
    "\n",
    "# Path for saving interemdiate objects, like NN predictions\n",
    "saved_data = f'{path_prefix}cached_data/'\n",
    "\n",
    "\n",
    "if not os.path.exists(saved_data):\n",
    "    print(f\"Making new directory for caching data {saved_data}\")\n",
    "    os.makedirs(saved_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ztautau', 'htautau', 'ttbar', 'diboson'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.detailed_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training['train_labels'] = -1 \n",
    "\n",
    "for key in labels_dict:\n",
    "    df_training.loc[df_training['detailed_labels'] == key, 'train_labels'] = labels_dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_hdf(f\"{saved_data}df_inclusive.h5\", key=\"dataset\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     mask_process \u001b[38;5;241m=\u001b[39m (df_training\u001b[38;5;241m.\u001b[39mdetailed_labels \u001b[38;5;241m==\u001b[39m label)\n\u001b[1;32m     10\u001b[0m     histograms[feature][label], bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mfeatures\u001b[49m[:, data_dict[feature]][mask_process], \n\u001b[1;32m     12\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights[mask_process], \n\u001b[1;32m     13\u001b[0m         bins\u001b[38;5;241m=\u001b[39mnbins\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     mask_process \u001b[38;5;241m=\u001b[39m (df_training\u001b[38;5;241m.\u001b[39mdetailed_labels \u001b[38;5;241m==\u001b[39m label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['PRI_lep_pt', 'PRI_lep_eta', 'PRI_met', 'PRI_met_phi', 'PRI_n_jets']\n",
    "\n",
    "histograms = {}\n",
    "for feature in columns:\n",
    "    histograms[feature] = {}\n",
    "    for count, label in enumerate(labels_dict):\n",
    "\n",
    "        if count==0:\n",
    "            mask_process = (df_training.detailed_labels == label)\n",
    "            histograms[feature][label], bins = np.histogram(\n",
    "                features[:, data_dict[feature]][mask_process], \n",
    "                weights=weights[mask_process], \n",
    "                bins=nbins\n",
    "            )\n",
    "        else:\n",
    "            mask_process = (df_training.detailed_labels == label)\n",
    "            histograms[feature][label], _ = np.histogram(\n",
    "                features[:, data_dict[feature]][mask_process], \n",
    "                weights=weights[mask_process], \n",
    "                bins=bins\n",
    "            )\n",
    "            \n",
    "        print(histograms[feature][label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training features to be used\n",
    "\n",
    "bins_dict = {\n",
    "    'PRI_lep_pt': np.linspace(10.0, 500.0, num=20),\n",
    "    'PRI_lep_eta': np.linspace(-2.5, 2.5, num=20),\n",
    "    'lep_phi': np.linspace(-2.5, 2.5, num=20),\n",
    "    'H_T': np.linspace(50.0, 2000.0, num=20),\n",
    "    'n_jets': np.linspace(-0.5, 4.5, num=6)\n",
    "}\n",
    "\n",
    "data_dict = {\n",
    "    'lep_pt': 0,  # Column index for lep_pt\n",
    "    'lep_eta': 1, # Column index for lep_eta\n",
    "    'lep_phi': 2, # Column index for lep_phi\n",
    "    'H_T': 3,     # Column index for H_T\n",
    "    'n_jets': 4       # Column index for n_jets\n",
    "}\n",
    "\n",
    "xlabel_dict = {\n",
    "    'lep_pt': 'lepton $p_T$ [GeV]', \n",
    "    'lep_eta': 'lepton $\\eta$ [GeV]', \n",
    "    'lep_phi': 'lepton $\\phi$ [GeV]', \n",
    "    'H_T': '$H_T$ [GeV]',     \n",
    "    'n_jets': '$n_{jets}$'      \n",
    "}\n",
    "\n",
    "histograms = {}\n",
    "for key, bin_edges in bins_dict.items():\n",
    "    histograms[key] = {}\n",
    "    for label in labels_dict:\n",
    "        mask_process = (train_labels == labels_dict[label])\n",
    "        histograms[key][label], _ = np.histogram(\n",
    "            features[:, data_dict[key]][mask_process], \n",
    "            weights=weights[mask_process], \n",
    "            bins=bin_edges\n",
    "        )\n",
    "        print(histograms[key][label])\n",
    "\n",
    "histograms_var_pT_res = {}\n",
    "for key, bin_edges in bins_dict.items():\n",
    "    histograms_var_pT_res[key] = {}\n",
    "    for label in labels_dict:\n",
    "        mask_process = (train_labels == labels_dict[label])\n",
    "        histograms_var_pT_res[key][label], _ = np.histogram(\n",
    "            features[:, data_dict[key]][mask_process], \n",
    "            weights=weights[mask_process], \n",
    "            bins=bin_edges\n",
    "        )\n",
    "\n",
    "\n",
    "palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "color_label_map = {\n",
    "    label: palette[i % len(palette)]\n",
    "    for i,label in enumerate(labels_dict)\n",
    "}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_labels = ['lep_pt', 'lep_eta', 'n_jets', 'H_T']\n",
    "\n",
    "for i, key in enumerate(plot_labels):\n",
    "    for label in labels_dict:\n",
    "        hep.histplot(histograms[key][label], bins=bins_dict[key], label=label, ax=axes[i], linewidth=1.5, color=color_label_map[label])\n",
    "        hep.histplot(histograms_var_pT_res[key][label], bins=bins_dict[key], label=f\"{label} pt_scale_up\", ax=axes[i], linewidth=1.5, linestyle='--', color=color_label_map[label])\n",
    "\n",
    "    axes[i].set_yscale('log')\n",
    "    axes[i].set_xlabel(xlabel_dict[key], size=16)\n",
    "    axes[i].set_ylabel('Events', size=16)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSBI",
   "language": "python",
   "name": "nsbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
