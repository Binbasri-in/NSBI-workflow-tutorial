{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Notebook\n",
    "===\n",
    "\n",
    "Prepare data for the analysis. The raw data is downloaded from the FAIR Universe HiggsML challenge repository. Use the HiggsML package to download and process the dataset, followed by selections and saving to local cache.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import yaml\n",
    "import uproot\n",
    "\n",
    "from utils import plot_kinematic_features\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from HiggsML.systematics import systematics\n",
    "hep.style.use(hep.style.ATLAS)\n",
    "\n",
    "from HiggsML.datasets import download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 06:09:42,961 - HiggsML.datasets     - INFO     - Handling as URL: https://zenodo.org/records/15131565/files/FAIR_Universe_HiggsML_data.zip\n",
      "2025-08-29 06:09:42,963 - HiggsML.datasets     - INFO     - Current working directory: /home/jsandesara_umass_edu/NSBI-workflow-tutorial/FAIR_universe_Higgs_tautau\n",
      "2025-08-29 06:09:43,030 - HiggsML.datasets     - INFO     - Total rows: 220099101\n",
      "2025-08-29 06:09:43,031 - HiggsML.datasets     - INFO     - Test size: 66029730\n"
     ]
    }
   ],
   "source": [
    "data = download_dataset(\"https://zenodo.org/records/15131565/files/FAIR_Universe_HiggsML_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 06:09:59,687 - HiggsML.datasets     - INFO     - Selected train size: 53924279\n",
      "2025-08-29 06:13:00,301 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data.load_train_set(train_size=0.35)\n",
    "df_training_full = data.get_train_set()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_processes_to_model = [\"htautau\", \"ztautau\", \"ttbar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diboson']\n"
     ]
    }
   ],
   "source": [
    "process_to_exclude = set(df_training_full[\"detailed_labels\"].unique()) - set(list_of_processes_to_model)\n",
    "process_to_exclude = list(process_to_exclude)\n",
    "print(process_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detailed_labels\n",
       "ztautau    34427142\n",
       "htautau    17850135\n",
       "ttbar       1517483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_process_exclusion = ~np.isin(df_training_full[\"detailed_labels\"], process_to_exclude)\n",
    "\n",
    "df_training_full = df_training_full[mask_process_exclusion].copy()\n",
    "df_training_full[\"detailed_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataset, so all processes have equal entries\n",
    "\n",
    "# get the number of ttbar events (lowest)\n",
    "n_ttbar = df_training_full.loc[\n",
    "    df_training_full.detailed_labels=='ttbar'\n",
    "].shape[0]\n",
    "\n",
    "# Trim the other processes to match ttbar number, preserving event weight sums\n",
    "df_list = []\n",
    "for _, df_process in df_training_full.groupby('detailed_labels'):\n",
    "\n",
    "    weight_sum_orig = df_process.weights.sum()\n",
    "\n",
    "    df_sampled = df_process.sample(n = n_ttbar, random_state=42)\n",
    "\n",
    "    df_sampled['weights'] *= weight_sum_orig / df_sampled['weights'].sum()\n",
    "\n",
    "    df_list.append(df_sampled)\n",
    "    \n",
    "    del df_sampled\n",
    "\n",
    "df_training = pd.concat(df_list).reset_index(drop=True)\n",
    "del df_training_full, df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_settings = {\n",
    "    'TES_up': {'tes': 1.02, 'seed': 42},\n",
    "    'TES_dn': {'tes': 0.98, 'seed': 42},\n",
    "    'JES_up': {'jes': 1.02, 'seed': 42},\n",
    "    'JES_dn': {'jes': 0.98, 'seed': 42}\n",
    "}\n",
    "\n",
    "\n",
    "dataset_dict = {}\n",
    "\n",
    "dataset_dict['nominal'] = systematics(\n",
    "        data_set = df_training,\n",
    "        dopostprocess=False\n",
    "        )\n",
    "\n",
    "for sample_name, syst_args in syst_settings.items():\n",
    "    dataset_dict[sample_name] = systematics(\n",
    "        data_set = df_training, \n",
    "        dopostprocess=False, \n",
    "        **syst_args\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_datasets = \"./saved_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some common analysis selections to remove low-stats regions\n",
    "selections = \"DER_mass_transverse_met_lep <= 250.0 and \\\n",
    "            DER_mass_vis <= 500.0 \\\n",
    "            and DER_sum_pt <= 1000 and \\\n",
    "            DER_pt_tot <= 250 and \\\n",
    "            DER_deltar_had_lep <= 4.5 and \\\n",
    "            DER_pt_h <= 400 and \\\n",
    "            DER_pt_ratio_lep_had <= 9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset_dict.keys():\n",
    "\n",
    "    # Write to ROOT TTree\n",
    "    with uproot.recreate(f\"{saved_datasets}dataset_{sample}.root\") as ntuple:\n",
    "\n",
    "        for process in list_of_processes_to_model:\n",
    "\n",
    "            df = dataset_dict[sample]\n",
    "            \n",
    "            df_process = df[df[\"detailed_labels\"] == process].copy()\n",
    "\n",
    "            df_process = df_process.query(selections).copy()\n",
    "\n",
    "            columns_to_keep = df_process.columns.tolist()\n",
    "\n",
    "            columns_to_keep = list(set(columns_to_keep) - set([\"detailed_types\"]))\n",
    "\n",
    "            arrays = {col: df_process[col].to_numpy() for col in columns_to_keep}\n",
    "\n",
    "            ntuple[f\"tree_{process}\"] = arrays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsbi_env_newish",
   "language": "python",
   "name": "nsbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
