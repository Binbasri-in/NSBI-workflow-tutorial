{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63f473bc-65f3-4d85-8715-a212abffeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib\n",
    "# sys.path.append('../')\n",
    "\n",
    "import nsbi_common_utils\n",
    "from nsbi_common_utils import plotting, training, inference\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import mplhep as hep\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "hep.style.use(hep.style.ATLAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e95d23e4-7fb8-4e83-a906-f3f691f4fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a skeleton workspace spec\n",
    "spec = {\n",
    "    \"channels\": [],\n",
    "    \"measurements\": [],\n",
    "    \"observations\": [],\n",
    "    \"version\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe1b6200-68f0-48ba-923d-148ce33b23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af161de9-be10-4b51-9bf2-a8aab85da9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SR_binned', 'CR']\n",
      "['SR']\n"
     ]
    }
   ],
   "source": [
    "# path prefix for general save directory\n",
    "path_prefix = config['path_prefix']\n",
    "\n",
    "# sub-path for saving cached data used between modules\n",
    "path_saved_data = config['path_saved_data']\n",
    "saved_data = f'{path_prefix}{path_saved_data}'\n",
    "\n",
    "# Get the dictionary of labels to processes\n",
    "labels_dict = config[\"labels_dict\"]\n",
    "\n",
    "# Signal processes in the model\n",
    "signal_processeses = config[\"signal_processes\"]\n",
    "\n",
    "# Background processes in the model\n",
    "background_processes = config[\"background_processes\"]\n",
    "\n",
    "mix_model_hypotheses = config[\"mix_model_hypotheses\"]\n",
    "ref_processes = config[\"ref_processes\"]\n",
    "\n",
    "all_process = signal_processeses + background_processes\n",
    "\n",
    "channels_binned = config[\"channels_binned\"]\n",
    "channels_unbinned = config[\"channels_unbinned\"]\n",
    "\n",
    "print(channels_binned)\n",
    "print(channels_unbinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "872559e9-4eb3-4a5f-a2f2-6f286c849503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1153/349965629.py:12: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  weights_Asimov = np.array(dataset[mask_Asimov].weights.ravel())\n"
     ]
    }
   ],
   "source": [
    "# Load the nominal dataset for evaluation\n",
    "dataset = pd.read_hdf(f\"{saved_data}dataset_preselected_nominal_SR.h5\", key=\"dataset\", mode='r')\n",
    "\n",
    "mask_processes = {}\n",
    "for process_type in all_process:\n",
    "    mask_processes[process_type] = dataset.type==process_type\n",
    "\n",
    "# Mask that extracts the expected Asimov dataset\n",
    "process_asimov = all_process\n",
    "\n",
    "mask_Asimov = np.logical_or.reduce([mask_processes[process_type] for process_type in process_asimov])\n",
    "weights_Asimov = np.array(dataset[mask_Asimov].weights.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3fe09af3-59e9-4273-9c61-34e596595407",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_workspace_data_nominal = f'{path_prefix}output_training_nominal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c39c71f-00c9-415d-aa7d-21783ba15b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_Asimov_weights = f\"{path_to_workspace_data_nominal}/weights_nominal_Asimov.npy\"\n",
    "np.save(path_to_Asimov_weights, weights_Asimov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52774015-cc7d-427a-999c-eecf7610271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_channels_list = []\n",
    "\n",
    "spec_channels_list.append(\n",
    "    {\n",
    "        \"name\": \"SR\",\n",
    "        \"type\": \"unbinned\",\n",
    "        \"weights\": path_to_Asimov_weights,\n",
    "        \"samples\": []\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65c3c593-f9f1-4d44-a5d6-14f4861b400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for process in all_process:\n",
    "    if process in mix_model_hypotheses:\n",
    "        path_to_ratio = f'{path_to_workspace_data_nominal}output_ratios_{process_type}/ratio_{process_type}.npy'\n",
    "        spec_channels_list[0][\"samples\"].append(\n",
    "            {\n",
    "                \"name\": process,\n",
    "                \"data\": path_to_ratio,\n",
    "                \"modifiers\":[\n",
    "                    {\n",
    "                        \"data\": None,\n",
    "                        \"name\": f\"mu_{process}\",\n",
    "                        \"type\": \"normfactor\",   \n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # The case where a sample is used as reference and thus has density ratio = 1 by default\n",
    "        spec_channels_list[0][\"samples\"].append(\n",
    "            {\n",
    "                \"name\": process,\n",
    "                \"data\": \"\",\n",
    "                \"modifiers\":[\n",
    "                    {\n",
    "                        \"data\": None,\n",
    "                        \"name\": f\"mu_{process}\",\n",
    "                        \"type\": \"normfactor\",   \n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "493799b2-93d1-4061-8907-3ce6aa73cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels_binned:\n",
    "    spec_channels_list.append(\n",
    "        {\n",
    "            \"name\": channel,\n",
    "            \"type\": \"binned\",\n",
    "            \"samples\": []\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with open(f\"{saved_data}hist_binned_{channel}.pkl\", \"rb\") as fp:\n",
    "            hist_channel = pickle.load(fp)\n",
    "        \n",
    "    for process in all_process:\n",
    "        \n",
    "        spec_channels_list[-1][\"samples\"].append(\n",
    "            {\n",
    "                \"name\": process,\n",
    "                \"data\": hist_channel[process].astype(float).tolist(),\n",
    "                \"modifiers\": [{\n",
    "                    \"data\": None,\n",
    "                    \"name\": f\"mu_{process}\",\n",
    "                    \"type\": \"normfactor\",  \n",
    "                }]\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf457a30-e0fe-475c-8d17-5c58d24243d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = {\n",
    "    \"channels\": spec_channels_list,\n",
    "    \"measurements\": [\n",
    "        {\n",
    "            \"name\": \"higgs_measurement\",\n",
    "            \"config\": {\n",
    "                \"poi\": \"mu_htautau\", \"parameters\": []\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"observations\": [],\n",
    "    \"version\": \"1.0.0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d2b39e8-1eaa-445a-9a5a-6a3698ed7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"workspace_stat_only.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spec, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c5436a3-c849-47eb-976d-9e87d192367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TES', 'JES']\n"
     ]
    }
   ],
   "source": [
    "path_to_dict_systs = f\"{saved_data}dict_systs.npy\"\n",
    "\n",
    "# Check if user has provided uncertainty NPs\n",
    "if \"dict_systs\" in config:\n",
    "    dict_systs = config[\"dict_systs\"]\n",
    "    # Load the SR yield variations\n",
    "    with open(f\"{saved_data}yield_SR_variations.pkl\", \"rb\") as fp:\n",
    "        nu_var_SR = pickle.load(fp)\n",
    "    # Save the Control Region variation histogram\n",
    "    with open(f\"{saved_data}hist_binned_variations.pkl\", \"rb\") as fp:\n",
    "        hist_variations = pickle.load(fp)\n",
    "else:\n",
    "    dict_systs = {}\n",
    "\n",
    "# Full list of systematics\n",
    "list_syst = [key for key in dict_systs]\n",
    "\n",
    "print(list_syst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f939d8e-fa22-408e-b7da-e984df37f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TES': {'process': ['htautau', 'ttbar', 'ztautau'],\n",
       "  'directions': ['up', 'dn']},\n",
       " 'JES': {'process': ['htautau', 'ttbar', 'ztautau'],\n",
       "  'directions': ['up', 'dn']}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_systs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3cec3a77-c65b-407b-b319-7003575c5358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_path_systematics = f'{path_prefix}output_training_systematics/'\n",
    "\n",
    "for syst, data in dict_systs.items():\n",
    "    \n",
    "    for process_dict in spec_channels_list[0][\"samples\"]:\n",
    "        \n",
    "        process_name = process_dict[\"name\"]\n",
    "        \n",
    "        if process_name in data[\"process\"]:\n",
    "\n",
    "            if \"up\" in data[\"directions\"]:\n",
    "                path = f'{top_path_systematics}output_ratios_{process_name}_{syst}_up/'\n",
    "                hi_data_path = f'{path}ratio_{syst}_up.npy'\n",
    "            else:\n",
    "                hi_data_path = \"\"\n",
    "                \n",
    "            if \"dn\" in data[\"directions\"]:\n",
    "                path = f'{top_path_systematics}output_ratios_{process_name}_{syst}_dn/'\n",
    "                lo_data_path = f'{path}ratio_{syst}_dn.npy'\n",
    "            else:\n",
    "                lo_data_path = \"\"\n",
    "            \n",
    "            process_dict[\"modifiers\"].append(\n",
    "                {\n",
    "                    \"data\": {\"hi_data\": hi_data_path, \"lo_data\": lo_data_path},\n",
    "                    \"name\": f\"alpha_{syst}\",\n",
    "                    \"type\": \"shapesys\"   \n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae34f96d-7013-4c0b-b932-427542a981a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_channel_index = {\n",
    "    'SR': 0,\n",
    "    'SR_binned': 1,\n",
    "    'CR': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6af8479d-2767-4032-b555-4897dd65847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spec_channels_list[dict_channel_index[channel_selected]][\"samples\"][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042b150-f87d-457f-898f-a82be52b9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selected =  'SR_binned'\n",
    "\n",
    "for syst, data in dict_systs.items():\n",
    "    \n",
    "    for process_dict in spec_channels_list[dict_channel_index[channel_selected]][\"samples\"]:\n",
    "        \n",
    "        process_name = process_dict[\"name\"]\n",
    "        \n",
    "        if process_name in data[\"process\"]:\n",
    "\n",
    "            if \"up\" in data[\"directions\"]:\n",
    "                hi_data = hist_variations[channel_selected][process_name][syst]['up']\n",
    "            else:\n",
    "                hi_data = np.ones(len(spec_channels_list[dict_channel_index[channel_selected]][\"samples\"][0]['data'])).astype(float).to_list()\n",
    "                \n",
    "            if \"dn\" in data[\"directions\"]:\n",
    "                lo_data = hist_variations[channel_selected][process_name][syst]['dn']\n",
    "            else:\n",
    "                lo_data = 2.0 - hi_data\n",
    "            \n",
    "            process_dict[\"modifiers\"].append(\n",
    "                {\n",
    "                    \"data\": {\"hi_data\": hi_data, \"lo_data\": lo_data},\n",
    "                    \"name\": f\"alpha_{syst}\",\n",
    "                    \"type\": \"shapesys\"   \n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5483964b-c9c0-4469-8053-42bd954ac61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SR_binned',\n",
       " 'type': 'binned',\n",
       " 'samples': [{'name': 'htautau',\n",
       "   'data': [1.3404816389083862],\n",
       "   'modifiers': [{'data': None, 'name': 'mu_htautau', 'type': 'normfactor'},\n",
       "    {'data': {'hi_data': array([1.0010142], dtype=float32),\n",
       "      'lo_data': array([0.9900152], dtype=float32)},\n",
       "     'name': 'alpha_TES',\n",
       "     'type': 'shapesys'},\n",
       "    {'data': {'hi_data': array([1.2158968], dtype=float32),\n",
       "      'lo_data': array([0.7761778], dtype=float32)},\n",
       "     'name': 'alpha_JES',\n",
       "     'type': 'shapesys'}]},\n",
       "  {'name': 'ttbar',\n",
       "   'data': [0.20330865681171417],\n",
       "   'modifiers': [{'data': None, 'name': 'mu_ttbar', 'type': 'normfactor'},\n",
       "    {'data': {'hi_data': array([1.], dtype=float32),\n",
       "      'lo_data': array([1.], dtype=float32)},\n",
       "     'name': 'alpha_TES',\n",
       "     'type': 'shapesys'},\n",
       "    {'data': {'hi_data': array([1.5734978], dtype=float32),\n",
       "      'lo_data': array([1.2855403], dtype=float32)},\n",
       "     'name': 'alpha_JES',\n",
       "     'type': 'shapesys'}]},\n",
       "  {'name': 'ztautau',\n",
       "   'data': [7.261922836303711],\n",
       "   'modifiers': [{'data': None, 'name': 'mu_ztautau', 'type': 'normfactor'},\n",
       "    {'data': {'hi_data': array([1.], dtype=float32),\n",
       "      'lo_data': array([0.9090909], dtype=float32)},\n",
       "     'name': 'alpha_TES',\n",
       "     'type': 'shapesys'},\n",
       "    {'data': {'hi_data': array([1.0909091], dtype=float32),\n",
       "      'lo_data': array([0.7272727], dtype=float32)},\n",
       "     'name': 'alpha_JES',\n",
       "     'type': 'shapesys'}]}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_channels_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d475fa2-e0e7-4a6f-b87d-3da34fb001b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSBI",
   "language": "python",
   "name": "nsbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
